#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Wed Apr  6 10:21:55 2022

@author: aixuexi
"""
import pickle
import numpy as np
import os
from tqdm import tqdm
from gensim.models import Word2Vec
from EmpiricalData import ExtractFilteredFoS
from EmpiricalData import ExtracAidFoS


# 主题的新旧程度
# 主题fos的组合数目
# 主题的流行度: Impact, Productivity / Human resource (Authors, Institutions)
# 主题的语义跨度: Word2Vec, PNAS下3个指标

threshold = ExtractFilteredFoS.filter_threshold
process_data_path = ExtracAidFoS.process_data_path  
      

def prepare_trainset():
    # 准备word2ec需要的trainset
    # 被CMySentences调用
    # 读取FoSData内信息
    filterfos2bornyear, _, _ = ExtractFilteredFoS.fos_born_year_data(threshold)
    # 将fos_list写一个.txt文件, 方便进行word2vec
    f_trainset = open(os.path.join(process_data_path, "trainset.txt"), 'w')
        
    i_list = ['0.0', '0.1', '0.2', '0.3'] + list(np.arange(1, 11))
    for i in i_list:
        aid2fosidx = ExtractFilteredFoS.filter_fos_data(filterfos2bornyear, i)
        for aid in aid2fosidx:
            for year in aid2fosidx[aid]:
                for pid, fos_list in aid2fosidx[aid][year]:
                    oneline = ','.join(fos_list)
                    f_trainset.write(oneline + "\n")
            
    f_trainset.close()


class CMySentences():
    # 迭代生成 word2vec需要的训练数据
    def __init__(self):
        # 读取所有的 fos_tuple
        self.path = os.path.join(process_data_path, "trainset.txt")
        if not os.path.exists(self.path):
            prepare_trainset()
        # 将fos_idx转变为fos_name
        with open(os.path.join(process_data_path, "idx2fos.pkl"), 'rb') as f:
            idx2fos = pickle.load(f)
        self.idx2fos = idx2fos
            
    def __iter__(self):
        for oneline in open(self.path, 'r'):
            fos_list = oneline.strip().split(',')
            fos_name_list = list()
            for fos in fos_list:
                if fos == '':
                    continue
                fos_name = self.idx2fos[int(fos)]
                # 一个fos name中可能含有空格
                fos_name_split = fos_name.split(" ")    
                fos_name_2 = "_".join(fos_name_split)
                fos_name_list.append(fos_name_2)
            yield fos_name_list
            

def train_word2vec():
    common_texts = CMySentences()
    # 创建模型
    model = Word2Vec()
    # internel dictionary tree structure
    model.build_vocab(common_texts)
    # train the neural model
    model.train(common_texts, 
                total_examples = model.corpus_count,
                epochs = model.iter)
    # 
    model.save(os.path.join(process_data_path, "word2vec.model"))
    # 词
    words = list(model.wv.vocab.keys())
    print("共计{}词".format(len(words)))
    # 向量
    word_vectors = model.wv
    word2vec = dict()
    for word in words:
        vec = word_vectors[word]
        word_list = word.split("_")
        word = " ".join(word_list) 
        word2vec[word] = vec
    # 存储
    with open(os.path.join(process_data_path, "word2vec.pkl"), 'wb') as f:
        pickle.dump(word2vec, f)


def test_word2vec():
    # 检验word2vec的质量
    with open(os.path.join(process_data_path, "word2vec.pkl"), 'rb') as f:
        word2vec = pickle.load(f)
        
    # fosvec 与 之最紧密cos联系的向量 (train_word2vec函数训练得到)
    fos2closedfos = dict()
    for word_i in tqdm(word2vec):
        vec_i = word2vec[word_i]
        cos_ij_list = list()
        for word_j in word2vec:
            vec_j = word2vec[word_j]
            if word_i != word_j:
                L_i = np.sqrt(vec_i.dot(vec_i))
                L_j = np.sqrt(vec_j.dot(vec_j))
                cos_ij = vec_i.dot(vec_j) / (L_i * L_j)
                cos_ij_list.append((word_j, cos_ij))
        cos_ij_list = sorted(cos_ij_list, key=lambda x: x[-1], reverse=True)
        cos_ij_list_top = cos_ij_list[:20]
        fos2closedfos[word_i] = cos_ij_list_top
    with open("./Word2Vec/fos2closedfos.pkl", 'wb') as f:
        pickle.dump(fos2closedfos, f)


    # 根据频率统计fos之间的共现关系
    filterfos2bornyear, _ = ExtractFilteredFoS.fos_born_year_data(threshold)
    fos2fos = dict() # fos之间的共现关系
    i_list = ['0.0', '0.1', '0.2', '0.3'] + list(np.arange(1, 11))
    for i in i_list:
        aid2fosidx = ExtractFilteredFoS.filter_fos_data(filterfos2bornyear, i)
        # 统计共现关系
        for aid in tqdm(aid2fosidx):
            for year in aid2fosidx[aid]:
                for pid, fos_list in aid2fosidx[aid][year]:
                    # 
                    for fos_i in fos_list:
                        if fos_i not in fos2fos:
                            fos2fos[fos_i] = dict()
                        for fos_j in fos_list:
                            if fos_j not in fos2fos[fos_i]:
                                fos2fos[fos_i][fos_j] = 1
                            else:
                                fos2fos[fos_i][fos_j] += 1
    del aid2fosidx
    # top 5 closed fos
    with open("./Statistical/idx2fos.pkl", 'rb') as f:
        idx2fos = pickle.load(f)
        
    fos2closedfos = dict()
    for fos in fos2fos:
        # top 5 频率邻居fos
        fos_j_list = fos2fos[fos].keys()
        fos_j_freq_list = [(fos_j, fos2fos[fos][fos_j]) for fos_j in fos_j_list]
        fos_j_freq_list = sorted(fos_j_freq_list, key=lambda x: x[-1], reverse=True)
        fos_j_freq_top_list = fos_j_freq_list[1:20+1]
        # 
        fos_name = idx2fos[int(fos)]
        fos_j_name_freq_top_list = [(idx2fos[int(fos_j)], freq) for fos_j, freq in fos_j_freq_top_list]
        fos2closedfos[fos_name] = fos_j_name_freq_top_list
    # save
    with open("./Word2Vec/fos2closedfos2.pkl", 'wb') as f:
        pickle.dump(fos2closedfos, f)


    # fos 与之高频组合的fos (extracted_closed_fos函数 计算得到)
    with open("./Word2Vec/fos2closedfos2.pkl", 'rb') as f:
        fos2closedfos2 = pickle.load(f)
    # 判断以上两者是否契合    
    with open("./Word2Vec/fos2closedfos.pkl", 'rb') as f:
        fos2closedfos = pickle.load(f)
        
    fos = 'feature based'
    fos2closedfos[fos]
    fos2closedfos2[fos]  # 只雇佣高频, 会偏好 level1等高层level, 因为他们的频率高


        
def Main():
    # 训练 word2vec
    train_word2vec()
    # 检查向量质量: 只能发现高频共现, cos相似度高
    # test_word2vec()
    