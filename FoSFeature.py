#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Thu Apr  7 09:22:58 2022

@author: aixuexi
"""
import numpy as np
import pickle
import seaborn as sns
import pandas as pd
import pymysql
import copy
import os
from tqdm import tqdm
import matplotlib.pyplot as plt
from matplotlib import rcParams
from PNAS_3Metrics import SpeedMetrics
from PNAS_3Metrics import MinVolEllips_Python
from PNAS_3Metrics import CircuitousnessMetrics
from PNAS_3Metrics import CosineMetrics
from PNAS_3Metrics import TimeDecayFunction
from EmpiricalData import ExtracAidFoS
from EmpiricalData import ExtractFilteredFoS

    
# Exploration behavior:
#    emerging topic selection strategy
#    combinatorial innovation topic selection strategy    

# Exploitation behvaior:
#    mature topic selection strategy
#    popular topic selection strategy
#    diverse topic selection strategy

process_data_path = ExtracAidFoS.process_data_path
save_data_path = '/mnt/disk2/EmpiricalData/ResearchStrategies'
threshold = ExtractFilteredFoS.filter_threshold
i_list = ['0.0', '0.1', '0.2', '0.3'] + list(np.arange(1, 11))

#%%
def calculate_dirverse_strategy():
    # 计算pid多样性程度: 语义空间向量的距离, 体积越大, 则知识越丰富
    # (1) 基于FoS2Vec生成的向量, 计算 平均距离, 体积, 迂回度
    
    with open(os.path.join(process_data_path, "idx2fos.pkl"), 'rb') as f:  # 读取 fos_idx 2 fos_name
        idx2fos = pickle.load(f)
    with open(os.path.join(process_data_path, "word2vec.pkl"), 'rb') as f: # 读取 fos_name 2 vex 
        word2vec = pickle.load(f)
    filterfos2bornyear, filterfostuple2bornyear, _ = ExtractFilteredFoS.fos_born_year_data(threshold)
    
    # 所有FoSTuple计算指标
    fostuple_list = list()   # fostuple列表
    avg_speed_list = list()  # 平均速度指标
    volume_list = list()     # 最小体积指标
    for fostuple in tqdm(filterfostuple2bornyear):
        fostuple_list.append(fostuple)
        fos_list = fostuple.split(',')
        fos_name_list = list()
        for fos in fos_list:
            if fos == '':
                continue
            fos_name_list.append(idx2fos[int(fos)])
        fos_vec_list = [word2vec[fos_name] for fos_name in fos_name_list] 
        fos_vec_arr = np.array(fos_vec_list).T
        
        # 计算两两向量距离的均值: 主题之间内容差异的宽度
        avg_speed = SpeedMetrics.CaculateSpeedMetrics(fos_vec_arr)
        avg_speed_list.append(avg_speed)
        
        # 计算向量覆盖的体积: 主题覆盖的知识面的广度
        volume = MinVolEllips_Python.CaculateVolumeMetrics(fos_vec_arr)
        volume_list.append(volume)
    
    fostuple2pnasmetrics = dict()
    for i, fostuple in enumerate(fostuple_list):
        speed = avg_speed_list[i]
        volume = volume_list[i]
        fostuple2pnasmetrics[fostuple] = (speed, volume)
    
    # 存放数据
    with open(os.path.join(save_data_path, "fostuple2pnasmetrics.pkl"), 'wb') as f:
        pickle.dump(fostuple2pnasmetrics, f)
    count1, count2 = 0, 0
    for i in fostuple2pnasmetrics:
        v, s = fostuple2pnasmetrics[i]
        if v == 0:
            count1 += 1
        if s == 0:
            count2 += 1
    print("占比{:.6f}的FoSTuple体积和距离为0 (异常)".format(count1 / len(fostuple2pnasmetrics)))
    
    # 整理成pid2pnasmetrics
    pid2pnasmetrics = dict()
    pid_duplicate_dict = dict()
    count_miss_list = list()
    for i in i_list:
        aid2fosidx = ExtractFilteredFoS.filter_fos_data(filterfos2bornyear, i)  # 作者每篇文章的 fos_list
        for aid in tqdm(aid2fosidx):
            for year in aid2fosidx[aid]:
                if year == '':
                    continue
                for pid, fos_list in aid2fosidx[aid][year]:
                    if pid not in pid_duplicate_dict:                  # 由于aid_part2fos是作者划分, 避免pid重复计数
                        pid_duplicate_dict[pid] = 0
                    else:
                        continue
                    # 过滤后非空
                    if len(fos_list) != 0:  
                       fos_tuple_name = ",".join(fos_list)
                       if fos_tuple_name in fostuple2pnasmetrics:
                           speed, volume  = fostuple2pnasmetrics[fos_tuple_name]
                           pid2pnasmetrics[pid] = (speed, volume)
                       else:
                           count_miss_list.append(fos_tuple_name)      # 可能由于 FoSFilter 没有set
                           speed, volume = 0, 0
                           pid2pnasmetrics[pid] = (speed, volume)
    del fostuple2pnasmetrics
    # 
    with open(os.path.join(save_data_path, "pid2pnasmetrics.pkl"), 'wb') as f:
        pickle.dump(pid2pnasmetrics, f)
        
        
#%%
def calculate_fos_popularity():
    # popularity = impact & productivity = citations & number of publications
    # 统计每个fos的逐年发文量和逐年引用量, 后续计算组合流行度
    filterfos2bornyear, _, _ = ExtractFilteredFoS.fos_born_year_data(threshold)
    
    fos2yearlynop = dict()     # 统计每个fos的逐年发文量
    fos2yearlycc  = dict()     # 统计每个fos的逐年被引用量
    pid_duplicate_dict = dict()
    for i in i_list:
        # 作者每篇文章的 fos_list
        aid2fosidx = ExtractFilteredFoS.filter_fos_data(filterfos2bornyear, i)  
        # 作者每篇文章的 citations
        pid2cc = ExtractFilteredFoS.fos_cc_data(i)                         
        # 统计流行度
        for aid in tqdm(aid2fosidx):
            for year in aid2fosidx[aid]:
                if year == '':
                    continue
                for pid, fos_list in aid2fosidx[aid][year]:
                    if pid not in pid_duplicate_dict:                  # 由于aid_part2fos是作者划分, 避免pid重复计数
                        pid_duplicate_dict[pid] = 0
                    else:
                        continue
                    pid2cc_each = pid2cc[pid]                          # 一篇文章的被引用计数情况
                    for fos in fos_list:
                        # 发文量计数
                        if fos not in fos2yearlynop:
                           fos2yearlynop[fos] = dict()
                        if year not in fos2yearlynop[fos]:
                           fos2yearlynop[fos][year] = np.array([0.0, 0.0])  # 全计数, 分数计数
                        fullcount = 1
                        fraccount = 1 / len(fos_list)
                        fos2yearlynop[fos][year] += np.array([fullcount, fraccount])
                        # 引用量计数
                        if fos not in fos2yearlycc:
                           fos2yearlycc[fos] = dict()
                        for year_cc in pid2cc_each:                         # year_cc > year, 引用滞后
                            if year_cc not in fos2yearlycc[fos]:
                               fos2yearlycc[fos][year_cc] = np.array([0.0, 0.0])   # 全计数, 分数计数
                            # 该篇pid在year_cc年的引用数目
                            cc = pid2cc_each[year_cc]
                            fullcount = 1 * cc
                            fraccount = 1 / len(fos_list) * cc
                            fos2yearlycc[fos][year_cc] += np.array([fullcount, fraccount])
    # 储存
    with open(os.path.join(save_data_path, "fos2yearlynop.pkl"), 'wb') as f:
        pickle.dump(fos2yearlynop, f)
    with open(os.path.join(save_data_path, "fos2yearlycc.pkl"), 'wb') as f:
        pickle.dump(fos2yearlycc, f)
    
    
def calculate_popularity_strategy():
    # 知识的流行性程度: 主题组在发文量和引用量占逐年整体比例越大, 则知识流行度越大
    # 计量每个fos tuple的组合流行度
    
    filterfos2bornyear, _, _ = ExtractFilteredFoS.fos_born_year_data(threshold)
    # 读取calculate_fos_popularity函数生成的数据
    with open(os.path.join(save_data_path, "fos2yearlynop.pkl"), 'rb') as f:
        fos2yearlynop = pickle.load(f)
    with open(os.path.join(save_data_path, "fos2yearlycc.pkl"), 'rb') as f:
        fos2yearlycc = pickle.load(f)
    # 每年所有fos的累计发文量 \sum_{fos} n_{fos}(t), Scientometrics文章34个level1, 比例的想法
    allfos2yearlynop = dict()
    for fos in fos2yearlynop:
        for year in fos2yearlynop[fos]:
            if year not in allfos2yearlynop:
                allfos2yearlynop[year] = np.zeros(2)
            allfos2yearlynop[year] += fos2yearlynop[fos][year]
    allfos2yearlycc = dict()
    for fos in fos2yearlycc:
        for year in fos2yearlycc[fos]:
            if year not in allfos2yearlycc:
                allfos2yearlycc[year] = np.zeros(2)
            allfos2yearlycc[year] += fos2yearlycc[fos][year]

    frac_signal = -1 # 采用分数计数法
    pid2popularitymetrics = dict() # 每篇文章的产量流行度指标 &  每篇文章的影响力流行度指标
    pid_duplicate_dict = dict()
    for i in i_list:
        # 读取作者fos_list列表
        aid2fosidx = ExtractFilteredFoS.filter_fos_data(filterfos2bornyear, i)
        for aid in tqdm(aid2fosidx):
            year_list = list(sorted(aid2fosidx[aid].keys())) # 作者的职业生涯跨度
            for year in year_list:
                if year == '':
                    continue
                for pid, fos_list in aid2fosidx[aid][year]:
                    if pid not in pid_duplicate_dict:                  # 由于aid_part2fos是作者划分, 避免pid重复计数
                        pid_duplicate_dict[pid] = 0
                    else:
                        continue
                    # 过滤后非空
                    if len(fos_list) != 0:
                       # 统计其popularity feature
                       fos_tuple_nop = 0
                       fos_tuple_cc  = 0
                       t_now =  year
                       # 当t_now年的fos发文量和引用量
                       for fos in fos_list:
                           if t_now in fos2yearlynop[fos]:
                              nop_t_now = fos2yearlynop[fos][t_now][frac_signal] # 分数计数法
                           else:
                              nop_t_now = 0
                           fos_tuple_nop += nop_t_now
                           if t_now in fos2yearlycc[fos]:
                               cc_t_now = fos2yearlycc[fos][t_now][frac_signal]  # 分数计数法
                           else:
                               cc_t_now = 0
                           fos_tuple_cc += cc_t_now
                           
                       # 当t_now年的所有fos构成的发文量和引用量
                       all_fos_nop = allfos2yearlynop[year][frac_signal]          # 当年的总发文量
                       if year in allfos2yearlycc:
                           all_fos_cc = allfos2yearlycc[year][frac_signal]        # 当年的引用量
                       else:
                           all_fos_cc = 1
                       production_metrics = fos_tuple_nop / all_fos_nop  # 该篇文章的fos tuple发文量占比
                       impact_metrics = fos_tuple_cc / all_fos_cc        # 该篇文章的fos tuple发文量占比
                       pid2popularitymetrics[pid] = (production_metrics, impact_metrics)
    # 储存
    with open(os.path.join(save_data_path, "pid2popularitymetrics.pkl"), 'wb') as f:
        pickle.dump(pid2popularitymetrics, f)


#%%
def calculate_bifos_popularity():
    # 统计每个fos的逐年发文量和逐年引用量, 后续计算组合流行度
    filterfos2bornyear, _, _ = ExtractFilteredFoS.fos_born_year_data(threshold)
    
    # 为采用分数计数法, 分数计算法应该是 1 / Cn2
    bifos2yearlynop = dict()
    pid_duplicate_dict = dict()
    for i in i_list:
        aid2fosidx = ExtractFilteredFoS.filter_fos_data(filterfos2bornyear, i)  # 作者每篇文章的 fos_list
        # 统计流行度
        for aid in tqdm(aid2fosidx):
            for year in aid2fosidx[aid]:
                if year == '':
                    continue
                for pid, fos_list in aid2fosidx[aid][year]:
                    if pid not in pid_duplicate_dict:                  # 由于aid_part2fos是作者划分, 避免pid重复计数
                        pid_duplicate_dict[pid] = 0
                    else:
                        continue
                    # 
                    if len(fos_list) > 1:  # 过滤后非空, 至少有2个fos (C_n^2)
                        for fos_i_index, fos_i in enumerate(fos_list):
                            for fos_j_index, fos_j in enumerate(fos_list[fos_i_index+1:]):
                                bi_fos_name = ",".join([fos_i, fos_j])
                                # 确定元组发文量计数
                                if bi_fos_name not in bifos2yearlynop:
                                    bifos2yearlynop[bi_fos_name] = dict()
                                if year not in bifos2yearlynop[bi_fos_name]:
                                    bifos2yearlynop[bi_fos_name][year] = 1
                                else:
                                    bifos2yearlynop[bi_fos_name][year] += 1  
    # 储存
    with open(os.path.join(save_data_path, "bifos2yearlynop.pkl"), 'wb') as f:
        pickle.dump(bifos2yearlynop, f)

def calculate_bifos_acc_popularity():
    # 将逐年的fos和bifos nop转换成累计nop
    
    # 读取fos逐年的发文量
    with open(os.path.join(save_data_path, "fos2yearlynop.pkl"), 'rb') as f:
        fos2yearlynop = pickle.load(f)
    # 读取bifos逐年的发文量
    with open(os.path.join(save_data_path, "bifos2yearlynop.pkl"), 'rb') as f:
        bifos2yearlynop = pickle.load(f)
            

    # 将其转变成fos逐年累计的发文量
    fos2accumulativeyearlynop = dict()
    for fos in tqdm(fos2yearlynop):
        fos2accumulativeyearlynop[fos] = dict()
        if '' in fos2yearlynop[fos]:
            del fos2yearlynop[fos]['']
        year_list = sorted(fos2yearlynop[fos].keys())
        for i, year_i in enumerate(year_list):
            accumlativeyearlynop = 0
            for j, year_j in enumerate(year_list[:i + 1]):  # 包含i时刻的之前所有累计nop
                yearlynop = fos2yearlynop[fos][year_j]
                accumlativeyearlynop += yearlynop
            fos2accumulativeyearlynop[fos][year_i] = accumlativeyearlynop    
    # 储存
    with open(os.path.join(save_data_path, "fos2accyearlynop.pkl"), 'wb') as f:
        pickle.dump(fos2accumulativeyearlynop, f)
    
    # 将其转变成fos逐年累计的发文量
    bifos2accumulativeyearlynop = dict()
    for fos in tqdm(bifos2yearlynop):
        bifos2accumulativeyearlynop[fos] = dict()
        if '' in bifos2yearlynop[fos]:
            del bifos2yearlynop[fos]['']
        year_list = sorted(bifos2yearlynop[fos].keys())
        for i, year_i in enumerate(year_list):
            accumlativeyearlynop = 0
            for j, year_j in enumerate(year_list[:i + 1]):  # 包含i时刻的之前所有累计nop
                yearlynop = bifos2yearlynop[fos][year_j]
                accumlativeyearlynop += yearlynop
            bifos2accumulativeyearlynop[fos][year_i] = accumlativeyearlynop      
    # 储存
    with open(os.path.join(save_data_path, "bifos2accyearlynop.pkl"), 'wb') as f:
        pickle.dump(bifos2accumulativeyearlynop, f)   


def calculate_mature_strategy():
    # 成熟主题利用度 --- ML (ML(fos), ML(fos_i)), MAP
    # 定义: 多么愿意巩固现有的知识结构
    # 读入accumulative yearly nop
    with open(os.path.join(save_data_path, "fos2accyearlynop.pkl"), 'rb') as f:
        fos2accumulativeyearlynop = pickle.load(f)
    with open(os.path.join(save_data_path, "bifos2accyearlynop.pkl"), 'rb') as f:
        bifos2accumulativeyearlynop = pickle.load(f)
    
    allfos2accumulativeyearlynop = dict()   # 截止t年的所有fos累计总量
    for fos in fos2accumulativeyearlynop:
        for year in fos2accumulativeyearlynop[fos]:
            if year not in allfos2accumulativeyearlynop:
                allfos2accumulativeyearlynop[year] = np.zeros(2)
            allfos2accumulativeyearlynop[year] += fos2accumulativeyearlynop[fos][year]
    allbifos2accumulativeyearlynop = dict() # 截止t年的所有bifos累计总量
    for bifos in bifos2accumulativeyearlynop:
        for year in bifos2accumulativeyearlynop[bifos]:
            if year not in allbifos2accumulativeyearlynop:
                allbifos2accumulativeyearlynop[year] = 0
            allbifos2accumulativeyearlynop[year] += bifos2accumulativeyearlynop[bifos][year]
    
    # 读取所有的fos_tuple
    filterfos2bornyear, _, _ = ExtractFilteredFoS.fos_born_year_data(threshold)
    #
    pid2maturemetrics = dict()
    pid_duplicate_dict = dict()
    for i in i_list:
        aid2fosidx = ExtractFilteredFoS.filter_fos_data(filterfos2bornyear, i)  # 作者每篇文章的 fos_list
        for aid in tqdm(aid2fosidx):
            for year in aid2fosidx[aid]:
                if year == '':
                    continue
                for pid, fos_list in aid2fosidx[aid][year]:
                    if pid not in pid_duplicate_dict:                  # 由于aid_part2fos是作者划分, 避免pid重复计数
                        pid_duplicate_dict[pid] = 0
                    else:
                        continue
                    # 过滤后非空
                    if len(fos_list) != 0:
                        # ML(fos)
                        loglikelihood_fos = list()
                        for fos in fos_list:
                            numerator = fos2accumulativeyearlynop[fos][year][-1]  # 分数计数法
                            denominator = allfos2accumulativeyearlynop[year][-1]  # 分数计数法
                            p_fos = numerator / denominator
                            # print(-np.log(p_fos))
                            loglikelihood_fos.append(-np.log(p_fos)) 
                        # 越小利用性越强, 利用现有高频知识单元
                        loglikelihood_fos_mean = np.mean(loglikelihood_fos)
                        
                        # ML(bi-fos)
                        loglikelihood_bifos = list()
                        if len(fos_list) > 1:  # 过滤后非空, 至少有2个fos
                            # C_n^2
                            for fos_i_index, fos_i in enumerate(fos_list):
                                for fos_j_index, fos_j in enumerate(fos_list[fos_i_index+1:]):
                                    bi_fos_name = ",".join([fos_i, fos_j])
                                    # 确定元组最早出现的年份
                                    numerator = bifos2accumulativeyearlynop[bi_fos_name][year]
                                    denominator = allbifos2accumulativeyearlynop[year]
                                    p_bifos = numerator / denominator
                                    # print(-np.log(p_bifos))
                                    loglikelihood_bifos.append(-np.log(p_bifos))
                        else:
                            loglikelihood_bifos.append(0)
                        # 越小利用性越强, 利用现有高频知识结构组合
                        loglikelihood_bifos_mean = np.mean(loglikelihood_bifos)
                        #
                        pid2maturemetrics[pid] = (loglikelihood_fos_mean, loglikelihood_bifos_mean)
                    
    del fos2accumulativeyearlynop, bifos2accumulativeyearlynop
    del allfos2accumulativeyearlynop, allbifos2accumulativeyearlynop
    # 储存
    with open(os.path.join(save_data_path, "pid2maturemetrics.pkl"), 'wb') as f:
         pickle.dump(pid2maturemetrics, f)


#%%
# 温度参数, 决定时间衰减曲线的衰减速率, 
# 详细请参见TimeDecayFunction模块
temperature = 20

def get_accumulative_nop_list(t, t0, fos, fos2noplist):
    # 读取 t0 - t 年逐年的fos发文量; 左闭 右开
    accumulative_production_list = list(fos2noplist[fos][t0: t, 1])  # fraccount 1, fullcount 0
    return accumulative_production_list

def time_decay_curve(t, t0):
    # t: 当前时刻, t0: 起始时刻
    time = np.arange(t0, t)
    # tdv = TimeDecayFunction.inverse_function_curve(time) # tdv = 1 / (time - t0 + 1)
    tdv = TimeDecayFunction.sigmoid_curve(time, temperature)
    #    
    return tdv

def accumulative_production_curve(accumulative_production_list):
    # accumulative_production_list: 逐年累计发文量列表
    apv = accumulative_production_list / accumulative_production_list[-1]
    return apv

# 为每个fos计算Novelty index
def calculate_ni_point(t, t0, fos, fos2noplist):
    # fos 累计发文量
    accumulative_production_list = get_accumulative_nop_list(t, t0, fos, fos2noplist)
    # tdv 和 apv 
    tdv = time_decay_curve(t, t0) 
    apv = accumulative_production_curve(accumulative_production_list)
    # time_decay_curve 与 accumulative_production_curve 交点, 即 novelty index
    minus = tdv - apv    
    minus_product = np.multiply(minus[:-1], minus[1:])
    interct_point_idx = np.argmin(minus_product)
    # 计算交点 (x, y)
    x1, x2 = interct_point_idx, interct_point_idx + 1
    y12, y11 = tdv[x1], apv[x1]
    y21, y22 = tdv[x2], apv[x2]
    # 
    k1 = (y22 - y11) / (x2 - x1)
    k2 = (y12 - y21) / (x1 - x2)
    b1 = y22 - k1 * x2
    b2 = y12 - k2 * x1
    x = (b2 - b1) / (k1 - k2)
    y = k1 * x + b1          
    # 绘图
    # plt.plot(np.arange(len(tdv)), tdv, marker='+', color='blue')
    # plt.plot(np.arange(len(apv)), apv, marker='*', color='red')
    return x, y
    
def calculate_emerging_strategy():
    # 知识的新颖性程度: 主题组内fos的novelty index得分, 其值越大, 表示主题新颖性越大

    filterfos2bornyear, _, _ = ExtractFilteredFoS.fos_born_year_data(threshold)
    # fos逐年的发文量
    with open(os.path.join(save_data_path, "fos2yearlynop.pkl"), 'rb') as f:
        fos2yearlynop = pickle.load(f)
    # 产生每个fos逐年累计发文量 (fos2noplist 和 fos2accumulativeyearlynop 类似)
    finalyear = 2021
    fos2noplist = dict()
    for fos in tqdm(fos2yearlynop):
        accumulativenoplist = list()
        bornyear = filterfos2bornyear[int(fos)]
        accnop = np.zeros(2)  # 全计数法 和 分数计数法
        for year in np.arange(bornyear, finalyear + 1):
            if year in fos2yearlynop[fos]:
               nop = fos2yearlynop[fos][year]
               accnop += nop
               accumulativenoplist.append(list(accnop))
            else:
               nop = np.zeros(2)
               accnop += nop
               accumulativenoplist.append(list(accnop))
        # 每个fos逐年累计发文量
        fos2noplist[fos] = np.array(accumulativenoplist)
    
    
    # 每篇文章的 NI 点的数值
    pid2nimetrics = dict()
    pid_duplicate_dict = dict()
    for i in i_list:
        aid2fosidx = ExtractFilteredFoS.filter_fos_data(filterfos2bornyear, i)  # 作者每篇文章的 fos_list
        # 统计新颖性    
        for aid in tqdm(aid2fosidx):
            for year in aid2fosidx[aid]:
                if year == '':
                    continue
                for pid, fos_list in aid2fosidx[aid][year]:
                    if pid not in pid_duplicate_dict:
                        pid_duplicate_dict[pid] = 0
                    else:
                        continue
                    if len(fos_list) != 0:
                        y_list = list()
                        for fos in fos_list:
                            bornyear = filterfos2bornyear[int(fos)]
                            t0 = bornyear - bornyear # 0   出生年份为0索引
                            t  = year - bornyear + 1 # + 1 是因为列表切片 noplist[t0: t]
                            if t > 1:
                                x, y = calculate_ni_point(t, t0, fos, fos2noplist)
                            else:
                                x, y = 0, 1
                            y_list.append(y)
                        # 均值和方差
                        ni_mean = np.mean(y_list)
                        ni_std  = np.std(y_list)
                        pid2nimetrics[pid]  = (ni_mean, ni_std)
    del pid_duplicate_dict, fos2yearlynop
    # 存储
    with open(os.path.join(save_data_path, "pid2nimetrics.pkl"), 'wb') as f:
        pickle.dump(pid2nimetrics, f)
          
#%%
def cosine_bi_fos():
    # 计算所有 bifos (fos组合二元组)的cosine similarity
    # cos similarity 是不同于 Euclidian distance的定义, 见笔记本
    with open(os.path.join(process_data_path, "idx2fos.pkl"), 'rb') as f:   # 读取 fos_idx 2 fos_name
        idx2fos = pickle.load(f)
    with open(os.path.join(process_data_path, "word2vec.pkl"), 'rb') as f:  # 读取 fos_name 2 vector 
        word2vec = pickle.load(f)
    # 读取所有的fos_tuple
    _, _, filterbifos2bornyear = ExtractFilteredFoS.fos_born_year_data(threshold)
    
    bifos2cos = dict()
    for bifos in tqdm(filterbifos2bornyear):
        fos_i, fos_j = bifos.split(",")
        # 语义相似度
        fos_vec_i = word2vec[idx2fos[int(fos_i)]]
        fos_vec_j = word2vec[idx2fos[int(fos_j)]]
        cos_ij = CosineMetrics.cos_metics(fos_vec_i, fos_vec_j)
        bifos2cos[bifos] = cos_ij
    
    with open(os.path.join(save_data_path, "bifos2cos.pkl"), 'wb') as f:
        pickle.dump(bifos2cos, f)
 
def caculate_combinational_innovation_strategy():    
    # 计算组合创新探索性程度: 越早将越语义差异大的主题组合在一起, 则探索性越强
    # temperature = 20 # nimetrics也涉及该参数
    # 将fos tuple 视作 bi fos的组合
    # 基于Fos2Vec生成的向量, 计算bi fos间的 cosine similarity
    
    with open(os.path.join(save_data_path, "bifos2cos.pkl"), 'rb') as f:
        bifos2cos = pickle.load(f)
    filterfos2bornyear, _, filterbifos2bornyear = ExtractFilteredFoS.fos_born_year_data(threshold)
    
    pid2cimetrics = dict()
    pid_duplicate_dict = dict()
    for i in i_list:
        aid2fosidx = ExtractFilteredFoS.filter_fos_data(filterfos2bornyear, i)  # 作者每篇文章的 fos_list
        for aid in tqdm(aid2fosidx):
            for year in aid2fosidx[aid]:
                if year == '':
                    continue
                for pid, fos_list in aid2fosidx[aid][year]:
                    if pid not in pid_duplicate_dict:                  # 由于aid_part2fos是作者划分, 避免pid重复计数
                        pid_duplicate_dict[pid] = 0
                    else:
                        continue
                    
                    if len(fos_list) == 1:  # 过滤后非空, 只有1个fos, 看作两个相同的fos自组合
                        explore_score_mean = 0
                        explore_score_std  = 0
                        pid2cimetrics[pid] = (explore_score_mean, explore_score_std)
                        
                    if len(fos_list) > 1:   # 过滤后非空, 至少有2个fos
                        # C_n^2
                        explore_score_list = list()
                        for fos_i_index, fos_i in enumerate(fos_list):
                            for fos_j_index, fos_j in enumerate(fos_list[fos_i_index+1:]):
                                bi_fos_name = ",".join([fos_i, fos_j])
                                # bifos的出生年份
                                bifos_bornyear = filterbifos2bornyear[bi_fos_name]
                                # 语义相似度
                                cos_ij = bifos2cos[bi_fos_name]
                                # 时间间隔
                                t = year - bifos_bornyear
                                t = max(0, t)
                                # 
                                time_effect = TimeDecayFunction.sigmoid_curve(t, temperature) # [0, 1]
                                simi_effect = 1 - cos_ij  # 不相似度 [0, 2]
                                explore_score = time_effect * simi_effect / 2
                                #
                                explore_score_list.append(explore_score)
                        # mean & std
                        explore_score_mean = np.mean(explore_score_list)
                        explore_score_std  = np.std(explore_score_list)
                        pid2cimetrics[pid] = (explore_score_mean, explore_score_std)
    
    with open(os.path.join(save_data_path, "pid2cimetrics.pkl"), 'wb') as f:
         pickle.dump(pid2cimetrics, f)
